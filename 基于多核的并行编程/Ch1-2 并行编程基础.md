# Ch1-2 并行编程基础

## 综述
* 并行编程：对给定算法构造并行程序的活动。
* 编程模型：程序员在开发一个并行程序时所见到和使用的模型。    * 自然模型：一个特定并行计算机平台所提供的、用户可见的最底层的编程模型。    * 高层编程模型：在自然模型上加以实现。
* 并行编程进展
    * 已开发了许多并行算法，尽管大多数算法基于PRAM模型，但其中某些经过修正后可以实用。
    * 并行算法已逐渐被用户所接受。
* 自然模型集中趋向于两种模型：单地址空间的共享变量模型（适用于PVP、SMP和DSM）和多地址空间的消息传递模型（适用于MPP和Cluster）。SIMD模型已经从主流、通用计算机淡出。
* 高层并行编程模型集中趋向于三种标准模型：数据并行、消息传递和共享变量。此外还有一种模型，用户只需编写顺序程序，其中的蕴式并行性由并行化编译器（如Kap）进行析取。

## 显式并行和隐式并行
* 显式并行
    * 在源程序中由程序员使用专用语言构造、编译器命令或库函数对并行性加以显式说明。
    * 包括共享变量模型、消息传递模型和数据并行模型。
* 隐式并行
    * 程序员不显式地说明并行性，而是让编译器或运行支持系统自动加以开发。
    * 包括并行化编译器、运行时间并行化。

## 并行化方法

### 环境支持（扩展Fortran或C）
* 例程库：除了在串行语言中可用的标准库外，加入一组新的库函数，以支持并行化和交互操作。例如MPI库、POSIX Pthread多线程库。
* 新构造：扩展程序设计语言使其具有某些新构造，以支持并行化和交互。例如Fortran 90中的密集数据操作。
* 编译器命令／预处理：程序设计语言不变，但加入编译器命令（pragmas）的格式化注解。

### 举例
* 串行代码

```C
for (i=0; i<N; i++) {
    A[i] = b[i] * b[i+1];
}
for (i=0; i<N; i++) {
    C[i] = A[i] + A[i+1];
}
```

* 使用库例程的等效并行代码

```Cid = my_process_id();p = number_of_processes();for (i=id; i<N; i+=p) {
    A[i] = b[i] * b[i+1];
    barrier();
}for (i=id; i<N; i+=p) {
    c[i] = A[i] + A[i+1];
}
```
* Fortran 90中使用数组操作的等效代码

```Fortran
my_process_id(), number_of_processes(), and barrier()
A(0:N-1) = b(0:N-1) * b(1:N)c = A(0:N-1) + A(1:N)
```

* SGI Power C中使用pragma的等效代码

```SGI Power C
#pragma parallel
#pragma shared (A, b, c)
#pragma local (i)
{
    #pragma pfor iterate (i=0; N; 1)
        for (i=0; i<N; i++) {
            A[i] = b[i] * b[i+1];
        }
    #pragma synchronize
    #pragma pfor iterate (i=0; N; 1)
        for (i=0; i<N; i++) {
            c[i] = A[i] + A[i+1];
        }
}
```

### 总结
| 方法 | 实例 | 优点 | 缺点 |
| --- | --- | --- | --- |
| 例程库 | MPI、PVM、Cray Craft | 易于实现，不需要新的编译器 | 无编译器检查、分析和优化 |
| 新构造 | Fortran 90、Cray Craft | 允许编译器检查、分析和优化 | 实现困难，需要新编译器，用户也需要学习新语言 |
| 编译器命令／预处理 | HPF、Cray Craft | 介于库例程和新构造方法之间 | 在串行平台上不起作用 |

## 显式并行编程模型
| 特点 | 数据并行 | 消息传递 | 共享存储 |
| --- | --- | --- | --- |
| 控制流（线程化） | 单控制流 | 多控制流 | 多控制流 |
| 同步 | 松散同步 | 异步 | 异步 |
| 地址空间 | 单地址空间 | 多地址空间 | 单地址空间 |
| 交互 | 隐式 | 显式 | 显式 |
| 数据分配 | 隐式／半显式 | 显式 | 隐式／半显式 |
| 并行粒度 | 进程级细粒度 | 进程级大粒度 | 线程级细粒度 |
| 数据存储模式 | 分布式存储 | 共享存储 | 共享存储 |
| 可移植性 | SMP、DSM、MPP | 所有主流并行计算机 | SMP、DSM |
| 典型代表 | HPF、IPP | MPI、PVM | OpenMP |
| 学习难度 | 偏易 | 较难 | 容易 |

## 其他并行编程模型：命令式语言以外的方法
* 函数式编程
* 逻辑编程
* 通过机器学习进行计算
* 面向对象编程

## 并行编程的策略和方法：分解（Decomposition）
将应用程序划分成多个独立的任务，并确定这些任务之间的相互依赖关系（相关性）。

### 分解方式
* 任务分解（Task Decomposition）：根据功能进行分解，是实现并行执行的最简单的方式。
* 数据分解（Data Decomposition）：根据处理的数据进行分解，对不同的数据集做相同的操作，类似SIMD，也叫数据级并行，可以有效地提高数据吞吐量。
* 数据流分解（Data Flow Decomposition）：根据数据流不同进行分解，即分解数据的处理阶段。

### 总结
| 分解方式 | 设计 | 说明 |
| --- | --- | --- |
| 任务分解 | 不同的程序行为采用不同的线程或进程实现 | 常用于GUI应用程序 |
| 数据分解 | 多个进程或线程对不同的数据块执行相同的操作 | 常用于音频、图像处理和科学计算应用程序 |
| 数据流分解 | 对数据处理阶段的不同操作进行分解 | 需要注意尽量消除启动和排空延迟 |

## 并行编程面对的挑战和问题
* 同步（Synchronization）：两个或多个线程／进程协调其行为的过程，例如一个线程停下来等待另一个线程。
* 通信（Communication）：线程／进程之间交互数据相关的带宽和延迟问题。
* 负载平衡（Load Balancing）：使线程或进程的工作量尽量平均分配。
* 可扩展性（Scalability）：在性能更强劲的系统上性能能否线性增长。

## 并行编程的设计模式

### 设计模式的概念
* 描述在特定上下文中解决重复问题的有效方法。
* 遵循一定的格式，包括：模式名、背景、面对的问题因素（即目标和限制）、解决方案。
* 其思想是记录专家经验，供遇到类似问题的其他人员参考。

### 任务并行模式：阶段并行（Phase Parallel）

#### 问题
* 问题被最好地分解为一个能够并发执行的任务集合时，如何高效地开发这种并行性。

#### 背景
* 设计直接基于任务。
* 并行算法以一个并发任务集合为基础。
* 识别任务及其相关性。

#### 面临问题
* 负载平衡。
* 管理任务相关性。

#### 示例
* 医学成像PET：对一系列的巨量图像进行处理。
    * 可以做任务并行，即按图像校正的不同处理过程分解。
    * 也可以做数据并行，即按人体部位分解。
* 分子动力学：
    * 数据分解：将一个大分子分解为多个部分。
    * 任务分解：将不同旋转方向的作用情况分别计算。

#### 解决方案
* 任务：两个标准
    * 任务的数目至少与处理单元的数目一样多。
    * 与每个任务相关的计算量必须足够多。
* 相关性：顺序约束，和共享有关的相关性。
* 调度：静态调度／动态调度。
* 程序结构：循环结构／任务队列。
* 常用术语：易并行问题、复制数据或规约问题。

#### 分阶段并行（Phase Parallel）
* 将程序分为若干个超步，每个超步包含两个阶段：计算阶段（Computation Phase）和交互阶段（Interaction Phase）。
* 又称为松散并行模式（Loosely Synchronous Paradigm）和日程模式（Agenda Paradigm）。

### 分治（Divide and Conquer）
* 主进程将工作分给多个子进程，子进程的结果最终再合并给主进程。
* 通常可以通过递归实现。
* 存在小部分不可并行的部分。
* 难点在于实现负载均衡，但是如果划分合理，各计算单元的负载就会比较均衡。

### 几何分解
* 将所要解决问题中使用的数据结构并行化。
* 每个线程只负责一些数据块上的操作。

### 流水线（Pipeline）
* 连续的数据流被放置进流水线。
* 处理器同时、重叠地处理流水线的不同阶段。

## 并行设计模式对应的分解方式
* 阶段并行：任务分解／数据分解
* 分治：任务分解／数据分解
* 几何分解模式：数据分解
* 流水线模式：数据流分解

